# -*- coding: utf-8 -*-
"""Loan Approval Prediction using Machine Learning .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19HOqJr2RUZvH5o5WPIpM2ah9iqKAVV9s
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import svm

df = pd.read_excel('loan.xlsx')

df.head()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import svm

# Ensure 'loan.xlsx' is in the correct directory or provide the full path.
df = pd.read_excel('loan.xlsx')

# Print some info to check if the DataFrame was loaded correctly.
df.info()

df.drop('Loan_ID', axis=1, inplace=True)

df.head()

df.info()

df.isnull().sum()

df['loanAmount_log'] = np.log(df['LoanAmount'])
df['loanAmount_log'].hist(bins=20)

df['TotalIncome'] = df['ApplicantIncome'] + df['CoapplicantIncome']
df['TotalIncome_log'] = np.log(df['TotalIncome'])
df['TotalIncome_log'].hist(bins=20)

df['Gender'].fillna(df['Gender'].mode()[0], inplace=True)
df['Married'].fillna(df['Married'].mode()[0], inplace=True)
df['Self_Employed'].fillna(df['Self_Employed'].mode()[0], inplace=True)
df['Dependents'].fillna(df['Dependents'].mode()[0], inplace=True)

df.isnull().sum()

df.LoanAmount = df.LoanAmount.fillna(df.LoanAmount.mean())
df.loanAmount_log = df.LoanAmount.fillna(df.loanAmount_log.mean())

df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].mode()[0], inplace=True)
df['Credit_History'].fillna(df.Credit_History.mode()[0], inplace=True)

df.isnull().sum()

x = df.drop('Loan_Status', axis=1)
y = df['Loan_Status']

y

print("per of missing is %2f%%" %((df['Gender'].isnull().sum()/df.shape[0])*100))

print("Number of People Who Take Loan As Per Gender")
print(df['Gender'].value_counts())
sns.countplot(x='Gender', data=df, palette='Set1')

print("Number of People Who Take Loan As Group By Marital Status:")
print(df['Married'].value_counts())
sns.countplot(x='Married', data=df, palette='Set1')

print("Number of People Who Take Loan As Group By Dependents:")
print(df['Dependents'].value_counts())
sns.countplot(x='Dependents', data=df, palette='Set1')

print("Number of People Who Take Loan As Group By Self_Employed:")
print(df['Self_Employed'].value_counts())
sns.countplot(x='Self_Employed', data=df, palette='Set1')

print("Number of People Who Take Loan As Group By Loanamount:")
print(df['LoanAmount'].value_counts())
sns.countplot(x='LoanAmount', data=df, palette='Set1')

print("Number of People Who Take Loan As Group By Credit_History:")
print(df['Credit_History'].value_counts())
sns.countplot(x='Credit_History', data=df, palette='Set1')

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

df.info()

df.head(2)

df['Property_Area'].unique()

df['Gender'] = le.fit_transform(df['Gender'])
df['Married'] = le.fit_transform(df['Married'])
df['Self_Employed'] = le.fit_transform(df['Self_Employed'])
df['Property_Area'] = le.fit_transform(df['Property_Area'])
df['Loan_Status'] = le.fit_transform(df['Loan_Status'])
df['Education'] = le.fit_transform(df['Education'])

df.head()

x = df.drop('Loan_Status', axis=1)
y = df['Loan_Status']

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)

# Convert 'Dependents' column to numeric representation before splitting
# Replace '3+' with 3 (or any suitable numeric value)
df['Dependents'] = df['Dependents'].replace('3+', 3)
df['Dependents'] = pd.to_numeric(df['Dependents'])

# Now proceed with data splitting and scaling
from sklearn.model_selection import train_test_split
x = df.drop('Loan_Status', axis=1)  # Define x after converting 'Dependents'
y = df['Loan_Status']
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

x_train.shape, x_test.shape, y_train.shape, y_test.shape

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

x_train

y_test

x_test

y_train

from sklearn.ensemble import RandomForestClassifier # Changed 'ensamble' to 'ensemble'
from sklearn.metrics import accuracy_score

model = RandomForestClassifier()
model.fit(x_train, y_train)

from sklearn.metrics import accuracy_score
y_pred = model.predict(x_test)
accuracy_score(y_test, y_pred)

from sklearn import metrics
print(metrics.classification_report(y_test, y_pred))

from sklearn.naive_bayes import GaussianNB
model = GaussianNB()
model.fit(x_train, y_train)

y_pred = model.predict(x_test)
accuracy_score(y_test, y_pred)

y_pred

from sklearn.tree import DecisionTreeClassifier
model = DecisionTreeClassifier()
model.fit(x_train, y_train)

y_pred = model.predict(x_test)
accuracy_score(y_test, y_pred)

y_pred

from sklearn.neighbors import KNeighborsClassifier
model = KNeighborsClassifier()
model.fit(x_train, y_train)

y_pred = model.predict(x_test)
accuracy_score(y_test, y_pred)

